import json
import os
import yaml
from tqdm import tqdm
import shutil
import random

def create_yolo_dataset(
        coco_json_path,
        yolo_labels_dir,
        image_dir,
        output_dir,
        ratios=(0.8, 0.1, 0.1),
        seed=42
):
    """
    åˆ›å»º YOLO æ ¼å¼çš„æ•°æ®é›†åˆ’åˆ†

    å‚æ•°:
        coco_json_path: COCO æ ¼å¼çš„ JSON æ–‡ä»¶è·¯å¾„
        yolo_labels_dir: YOLO æ ¼å¼çš„æ ‡ç­¾ç›®å½•
        image_dir: å›¾åƒæ–‡ä»¶ç›®å½•
        output_dir: è¾“å‡ºç›®å½•
        ratios: (è®­ç»ƒé›†æ¯”ä¾‹, éªŒè¯é›†æ¯”ä¾‹, æµ‹è¯•é›†æ¯”ä¾‹)
        seed: éšæœºç§å­
    """
    # éªŒè¯æ¯”ä¾‹æ€»å’Œä¸º1
    if abs(sum(ratios) - 1.0) > 0.01:
        raise ValueError(f"æ¯”ä¾‹æ€»å’Œå¿…é¡»ä¸º1.0ï¼Œå½“å‰ä¸º: {sum(ratios)}")

    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    for folder in ['labels', 'images']:
        for subset in ['train', 'val', 'test']:
            os.makedirs(os.path.join(output_dir, folder, subset), exist_ok=True)

    # åŠ è½½ COCO æ•°æ®
    with open(coco_json_path, 'r') as f:
        coco_data = json.load(f)

    # 1. æå–ç±»åˆ«ä¿¡æ¯
    categories = coco_data['categories']
    nc = len(categories)
    sorted_categories = sorted(categories, key=lambda x: x['id'])
    class_names = [cat['name'] for cat in sorted_categories]
    class_ids = [cat['id'] for cat in sorted_categories]

    print(f"ðŸ“Š æ•°æ®é›†ç»Ÿè®¡:")
    print(f"  ç±»åˆ«æ•°é‡: {nc}")
    print(f"  ç±»åˆ«åˆ—è¡¨: {', '.join(class_names)}")

    # 2. æž„å»ºå›¾åƒåˆ—è¡¨
    images = coco_data['images']
    image_files = {}

    print("\nðŸ” æž„å»ºå›¾åƒåˆ—è¡¨...")
    for img in tqdm(images):
        file_name = img['file_name']
        base_name = file_name.split('.')[0]

        # æŸ¥æ‰¾å¯¹åº”çš„YOLOæ ‡ç­¾æ–‡ä»¶
        label_file = os.path.join(yolo_labels_dir, f"{base_name}.txt")

        # æ£€æŸ¥å›¾ç‰‡æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        img_path = os.path.join(image_dir, file_name)
        if not os.path.exists(img_path):
            print(f"âš ï¸ è­¦å‘Š: å›¾ç‰‡æ–‡ä»¶ç¼ºå¤± - {img_path}")
            continue

        # æ£€æŸ¥æ ‡ç­¾æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(label_file):
            print(f"âš ï¸ è­¦å‘Š: æ ‡ç­¾æ–‡ä»¶ç¼ºå¤± - {label_file}")
            continue

        image_files[base_name] = {
            'coco_image': img,
            'image_path': img_path,
            'label_path': label_file
        }

    total_images = len(image_files)
    print(f"âœ… æ‰¾åˆ° {total_images} ä¸ªæœ‰æ•ˆå›¾åƒ-æ ‡ç­¾å¯¹")

    if total_images == 0:
        print("âŒ é”™è¯¯: æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„å›¾åƒ-æ ‡ç­¾å¯¹")
        exit(1)

    # 3. éšæœºåˆ’åˆ†æ•°æ®é›†
    random.seed(seed)
    all_keys = list(image_files.keys())
    random.shuffle(all_keys)

    train_end = int(ratios[0] * total_images)
    val_end = train_end + int(ratios[1] * total_images)

    splits = {
        'train': all_keys[:train_end],
        'val': all_keys[train_end:val_end],
        'test': all_keys[val_end:]
    }

    # 4. å¤åˆ¶æ–‡ä»¶å¹¶åˆ›å»ºç´¢å¼•
    print("\nðŸ“‚ å¤åˆ¶æ–‡ä»¶åˆ°ç›®æ ‡ç›®å½•...")
    index_files = {}
    class_counts = {subset: {cls_id: 0 for cls_id in class_ids} for subset in splits}

    print(class_counts)

    for subset, keys in splits.items():
        index_files[subset] = []

        print(f"  å¤„ç† {subset} é›† ({len(keys)} ä¸ªæ ·æœ¬)")
        for key in tqdm(keys, desc=f"{subset} é›†"):
            data = image_files[key]

            # å¤åˆ¶å›¾åƒæ–‡ä»¶
            img_file = data['coco_image']['file_name']
            img_src = data['image_path']
            img_dest = os.path.join(output_dir, 'images', subset, img_file)
            shutil.copy2(img_src, img_dest)

            # å¤åˆ¶æ ‡ç­¾æ–‡ä»¶
            label_src = data['label_path']
            label_file = os.path.basename(label_src)
            label_dest = os.path.join(output_dir, 'labels', subset, label_file)
            shutil.copy2(label_src, label_dest)

            # æ·»åŠ åˆ°ç´¢å¼•æ–‡ä»¶
            index_files[subset].append(os.path.abspath(img_dest))

            # ç»Ÿè®¡ç±»åˆ«åˆ†å¸ƒ
            with open(label_src, 'r') as f:
                for line in f:
                    parts = line.split()
                    if parts:
                        cls_id = int(parts[0])
                        print(f'label:{label_src},cls_id:{cls_id}')
                        class_counts[subset][cls_id] += 1

        # å†™å…¥ç´¢å¼•æ–‡ä»¶
        with open(os.path.join(output_dir, f"{subset}.txt"), 'w') as f:
            for path in index_files[subset]:
                f.write(path + "\n")

    # 5. åˆ›å»º data.yaml é…ç½®æ–‡ä»¶
    yaml_content = {
        'path': os.path.abspath(output_dir),
        'train': os.path.abspath(os.path.join(output_dir, 'train.txt')),
        'val': os.path.abspath(os.path.join(output_dir, 'val.txt')),
        'test': os.path.abspath(os.path.join(output_dir, 'test.txt')),

        'nc': nc,
        'names': class_names,

        'class_ids': class_ids,

        'dataset_stats': {
            'total_images': total_images,
            'subsets': {}
        }
    }

    # æ·»åŠ å­é›†ç»Ÿè®¡ä¿¡æ¯
    for subset in splits:
        yaml_content['dataset_stats']['subsets'][subset] = {
            'image_count': len(splits[subset]),
            'class_distribution': {
                class_names[i]: class_counts[subset][class_ids[i]]
                for i in range(nc)
            }
        }

    # ä¿å­˜YAMLæ–‡ä»¶
    yaml_path = os.path.join(output_dir, 'data.yaml')
    with open(yaml_path, 'w') as f:
        yaml.dump(yaml_content, f, default_flow_style=False)

    print(f"\nâœ… YOLOæ•°æ®é›†åˆ›å»ºå®Œæˆ!")
    print(f"ðŸ“ è¾“å‡ºç›®å½•: {os.path.abspath(output_dir)}")
    print(f"ðŸ“„ é…ç½®æ–‡ä»¶: {yaml_path}")

    # æ‰“å°è¯¦ç»†ç»Ÿè®¡
    print("\nðŸ“Š æ•°æ®é›†åˆ’åˆ†ç»Ÿè®¡:")
    for subset in splits:
        count = len(splits[subset])
        print(f"  {subset.upper()}: {count} ä¸ªå›¾åƒ ({count / total_images:.1%})")
        for cls_name in class_names:
            cls_id = class_ids[class_names.index(cls_name)]
            c_count = class_counts[subset][cls_id]
            if c_count > 0:
                print(f"    {cls_name}: {c_count} ä¸ªæ ‡æ³¨")

    return yaml_path

create_yolo_dataset(
    coco_json_path='../data/child/merged_annotations.json',
    yolo_labels_dir='../data/dataset/yolo',
    image_dir='../data/dataset/coco/crop_child/images/images',
    output_dir='../data/dataset/yolo_child'
)