import json
import random
from pathlib import Path
from typing import Dict, List, Any
from pycocotools.coco import COCO



def _create_json_files(
    full_coco_data: Dict[str, Any],
    split_definition: Dict[str, List[int]],
    output_dir: Path
) -> None:
    for subset_name, subset_ids in split_definition.items():
        print(f"\n  æ­£åœ¨ç”Ÿæˆ '{subset_name}.json'...")
        subset_id_set = set(subset_ids)
        subset_images = [img for img in full_coco_data['images'] if img['id'] in subset_id_set]
        subset_annotations = [ann for ann in full_coco_data['annotations'] if ann['image_id'] in subset_id_set]
        subset_data = {"info": full_coco_data.get("info", {}), "licenses": full_coco_data.get("licenses", []), "categories": full_coco_data["categories"], "images": subset_images, "annotations": subset_annotations}
        output_path = output_dir / f"{subset_name}.json"
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(subset_data, f, indent=4)
        print(f"  âœ… å·²ç”Ÿæˆ '{subset_name}.json': {len(subset_images)} å¼ å›¾ç‰‡, {len(subset_annotations)} ä¸ªæ ‡æ³¨ã€‚")


def create_coco_efficiency_files(
        annotation_path: Path,
        output_dir: Path,
        master_split: Dict[str, List[int]],
        percentages: List[int] = [20, 40, 60, 80, 100]
) -> None:
    """
    æ¥æ”¶ä¸€ä¸ªé¢„å…ˆåˆ’åˆ†å¥½çš„IDå­—å…¸ï¼Œä¸ºCOCOæ•°æ®é›†ç”Ÿæˆæ•ˆç‡å®éªŒæ–‡ä»¶ã€‚

    :param annotation_path: åŸå§‹COCOå®Œæ•´æ ‡æ³¨æ–‡ä»¶çš„è·¯å¾„ã€‚
    :param output_dir: è¾“å‡ºç›®å½•ã€‚
    :param master_split: é¢„å…ˆåˆ’åˆ†å¥½çš„IDå­—å…¸ï¼Œå¿…é¡»åŒ…å« 'train_pool', 'val', 'test' é”®ã€‚
    :param percentages: éœ€è¦ç”Ÿæˆçš„è®­ç»ƒé›†ç™¾åˆ†æ¯”åˆ—è¡¨ã€‚
    """
    output_dir.mkdir(parents=True, exist_ok=True)

    print(f"æ­£åœ¨åŠ è½½åŸå§‹COCOæ ‡æ³¨æ–‡ä»¶: {annotation_path}")
    coco = COCO(str(annotation_path))
    data = coco.dataset
    print("åŠ è½½å®Œæˆã€‚")

    # ä»master_splitä¸­æå–ID
    val_ids = master_split['val']
    test_ids = master_split['test']
    train_pool_ids = master_split['train']

    # ç”Ÿæˆå›ºå®šçš„éªŒè¯é›†å’Œæµ‹è¯•é›†JSON
    print("\næ­£åœ¨ç”Ÿæˆå›ºå®šçš„COCOéªŒè¯é›†å’Œæµ‹è¯•é›†æ–‡ä»¶...")
    _create_json_files(data, {'val': val_ids, 'test': test_ids}, output_dir)

    # æ ¹æ®ç™¾åˆ†æ¯”ç”Ÿæˆè®­ç»ƒé›†JSON
    print("\næ­£åœ¨æ ¹æ®ç™¾åˆ†æ¯”ç”ŸæˆCOCOè®­ç»ƒé›†æ–‡ä»¶...")
    random.shuffle(train_pool_ids)  # å†æ¬¡æ‰“ä¹±ä»¥ä¿è¯åˆ‡ç‰‡çš„éšæœºæ€§

    for p in sorted(percentages):
        num_to_sample = int(len(train_pool_ids) * (p / 100))
        subset_train_ids = train_pool_ids[:num_to_sample]
        subset_name = f"train_{p}"
        _create_json_files(data, {subset_name: subset_train_ids}, output_dir)

    print("\nğŸ‰ æ‰€æœ‰COCOæ•ˆç‡å®éªŒæ•°æ®é›†å·²ç”Ÿæˆå®Œæ¯•ï¼")


if __name__ == '__main__':
    # parser = argparse.ArgumentParser(description="COCO æ•°æ®é›†åˆ’åˆ†å·¥å…·")
    # parser.add_argument('--json', type=str, required=True, help='åŸå§‹ COCO æ ‡æ³¨æ–‡ä»¶è·¯å¾„')
    # parser.add_argument('--output', type=str, required=True, help='è¾“å‡ºç›®å½•è·¯å¾„')
    # parser.add_argument('--ratios', type=float, nargs=3, default=[0.7, 0.2, 0.1],
    #                     help='åˆ’åˆ†æ¯”ä¾‹ï¼ˆè®­ç»ƒé›† éªŒè¯é›† æµ‹è¯•é›†ï¼‰ï¼Œä¾‹å¦‚ 0.7 0.2 0.1')
    # parser.add_argument('--seed', type=int, default=42, help='éšæœºç§å­ï¼ˆé»˜è®¤ï¼š42ï¼‰')
    # args = parser.parse_args()

    annotation_path = '../data/dataset/coco/crop_child/annotations/merged_annotations.json'
    output_dir = '../data/dataset/coco/crop_child/annotations'

